{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, Lambda, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_first\n"
     ]
    }
   ],
   "source": [
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/naka345/Desktop/deeplearning/car_number/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "num_predictions = 20\n",
    "save_dir = f'{root_dir}model/'\n",
    "model_name = 'plate_detect_trained_model.h5'\n",
    "load_dir_path = 'output/train'\n",
    "\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/naka345/Desktop/deeplearning/car_number/output/train\n"
     ]
    }
   ],
   "source": [
    "path = root_dir + load_dir_path\n",
    "import glob\n",
    "print(path)\n",
    "x_path = glob.glob(f'{path}/20190123/*.JPG')\n",
    "y_path = glob.glob(f'{path}/20190123/*.csv')\n",
    "x_path.sort()\n",
    "import pandas as pd\n",
    "y_t_df = pd.read_csv(y_path[0],index_col=0).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_list = [(img_to_array(load_img(x))/255.) for x in x_path]\n",
    "x_train = np.array(x_list)\n",
    "x_shape =  x_train.shape\n",
    "print(x_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lu_x', 'lu_y', 'ru_x', 'ru_y', 'ld_x', 'ld_y', 'rd_x', 'rd_y'], dtype='object')\n",
      "[[136.         157.24137931 160.         156.32183908 136.55172414\n",
      "  177.47126437 160.         177.01149425]]\n"
     ]
    }
   ],
   "source": [
    "label = y_t_df.columns\n",
    "y_train = y_t_df.values\n",
    "print(y_t_df.columns)\n",
    "print(y_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\n                    validation_data=(x_test, y_test),\\n                    epochs=epochs, verbose=1, workers=4,\\n                    callbacks=callbacks)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    rotation_range=15,\n",
    "    # randomly shift images horizontally\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    height_shift_range=0.1,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.1,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "#datagen.fit(x_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "'''\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136.         157.24137931 160.         156.32183908 136.55172414\n",
      "  177.47126437 160.         177.01149425]]\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_validation_split', 'apply_transform', 'brightness_range', 'channel_axis', 'channel_shift_range', 'col_axis', 'cval', 'data_format', 'dtype', 'featurewise_center', 'featurewise_std_normalization', 'fill_mode', 'fit', 'flip_rate', 'flow', 'flow_from_dataframe', 'flow_from_directory', 'get_random_transform', 'height_shift_range', 'horizontal_flip', 'label', 'label_x', 'label_y', 'mean', 'preprocessing_function', 'principal_components', 'random_transform', 'rescale', 'rotation_range', 'row_axis', 'samplewise_center', 'samplewise_std_normalization', 'shear_range', 'standardize', 'std', 'vertical_flip', 'vf_corres', 'width_shift_range', 'x_ttt', 'xy_horizontal_flip', 'xy_zoom_range', 'y_ttt', 'zca_epsilon', 'zca_whitening', 'zoom_range']\n",
      "[]\n",
      "horizontal_flip\n",
      "[0.7430721685861658]\n",
      "[0.9635706465997408]\n",
      "final_affine_matrix [[0.74307217 0.        ]\n",
      " [0.         0.96357065]]\n",
      "final_offset [0. 0.]\n",
      "[[136.         160.         136.55172414 160.        ]\n",
      " [157.24137931 156.32183908 177.47126437 177.01149425]\n",
      " [  1.           1.           1.           1.        ]]\n",
      "[[0.74307217 0.         0.        ]\n",
      " [0.         0.96357065 0.        ]\n",
      " [0.         0.         1.        ]]\n",
      "[101.057816 151.51318  118.89155  150.62714  101.46779  171.0061\n",
      " 118.89155  170.56308 ]\n",
      "y_generated:[[  0.           0.           0.           0.           0.\n",
      "    0.           0.           0.        ]\n",
      " [101.05781555 151.51318359 118.89154816 150.62713623 101.4677887\n",
      "  171.00610352 118.89154816 170.56307983]]\n",
      "[[101.05781555 151.51318359 118.89154816 150.62713623 101.4677887\n",
      "  171.00610352 118.89154816 170.56307983]]\n"
     ]
    }
   ],
   "source": [
    "class CustomedImageDataGenerator(ImageDataGenerator):\n",
    "    label_x = ['lu_x','ru_x','ld_x','rd_x',]\n",
    "    label_y = ['lu_y','ru_y','ld_y','rd_y',]\n",
    "    label=['lu_x', 'lu_y', 'ru_x', 'ru_y', 'ld_x', 'ld_y', 'rd_x', 'rd_y']\n",
    "    vf_corres = [(0,2),(1,3),(4,6),(5,7)]\n",
    "    flip_rate = 0.5\n",
    "    \n",
    "    def flow(self, x_data, y_data):\n",
    "        self.x_ttt = x_data[0:10]\n",
    "        self.y_ttt = y_data[0:10]\n",
    "        #t_im=self.x_ttt[0].transpose((1,2,0))*255\n",
    "        #cv2.imwrite(\"./tt.jpg\",t_im)\n",
    "        \n",
    "        width_shift_range = self.width_shift_range\n",
    "        height_shift_range = self.height_shift_range\n",
    "        rotation_range = self.rotation_range\n",
    "        zoom_range = self.zoom_range\n",
    "        horizontal_flip = self.horizontal_flip\n",
    "        vertical_flip = self.vertical_flip\n",
    "        \n",
    "        super().__init__()\n",
    "        X_batch = super().flow(self.x_ttt, y=self.y_ttt)\n",
    "        \n",
    "        print(dir(X_batch.image_data_generator))\n",
    "        X_data = X_batch[0][0]\n",
    "        y_data = X_batch[0][1]\n",
    "\n",
    "        data_length = X_data.shape[0]\n",
    "        batch_size = X_batch.batch_size\n",
    "        \n",
    "        if data_length < batch_size:\n",
    "            batch_size = data_length\n",
    "        \n",
    "        indices = np.random.choice(batch_size, int(batch_size*self.flip_rate), replace=False)\n",
    "        print(indices)\n",
    "        \n",
    "        \n",
    "        if horizontal_flip:\n",
    "            print(\"horizontal_flip\")\n",
    "            X_data[indices] = X_data[indices, :, :, ::-1]\n",
    "            y_data = self.xy_horizontal_flip(indices, y_data)\n",
    "            \n",
    "        if rotation_range != 0:\n",
    "            print('rotation_range')\n",
    "            \n",
    "        if width_shift_range != 0:\n",
    "            print('width_shift_range')\n",
    "            \n",
    "        if height_shift_range != 0:\n",
    "            print('height_shift_range')\n",
    "            \n",
    "        if zoom_range != 0:\n",
    "            if isinstance(zoom_range,float):\n",
    "                zoom_range_list = [zoom_range * -1, zoom_range]\n",
    "                zoom_batch_x, zoom_batch_y = self.xy_zoom_range(zoom_range_list, batch_size)\n",
    "            else:\n",
    "                zoom_batch_x, zoom_batch_y = self.xy_zoom_range(zoom_range, batch_size)\n",
    "        \n",
    "        if vertical_flip:\n",
    "            print('vertical_flip')\n",
    "            \n",
    "        #return X_batch\n",
    "        \n",
    "        x_generated = np.zeros((1,3,200,200))\n",
    "        y_generated = np.zeros((1,8))\n",
    "        print(zoom_batch_x)\n",
    "        print(zoom_batch_y)\n",
    "        for x,y,zx,zy in zip(X_data, y_data, zoom_batch_x, zoom_batch_y):\n",
    "            x,y = apply_affine_transform(x,y, zx=zx, zy=zy, channel_axis=0,\n",
    "                               fill_mode=\"nearest\", cval=0,\n",
    "                               order=1)\n",
    "            \n",
    "            x = x.reshape(1,3,200,200)\n",
    "            x_generated = np.vstack((x_generated, x))\n",
    "            y_generated = np.vstack((y_generated, y))\n",
    "        print(f\"y_generated:{y_generated}\")\n",
    "        return x_generated[1:], y_generated[1:]\n",
    "    \n",
    "    def xy_horizontal_flip(self, indices, y_data):\n",
    "        y_data[indices, ::2] =1- y_data[indices, ::2]\n",
    "        for a,b in self.vf_corres:\n",
    "            y_data[indices,a], y_data[indices,b] = (y_data[indices,b] ,y_data[indices,a])\n",
    "        return y_data\n",
    "    \n",
    "    def xy_zoom_range(self,zoom_range,batch_size):\n",
    "        if len(zoom_range) != 2:\n",
    "            raise ValueError('`zoom_range` should be a tuple or list of two'\n",
    "                         ' floats. Received: %s' % (zoom_range,))\n",
    "        \n",
    "        batch_zx = []\n",
    "        batch_zy = []\n",
    "        for i in range(batch_size):\n",
    "            if zoom_range[0] == 1 and zoom_range[1] == 1:\n",
    "                zx, zy = 1, 1\n",
    "            else:\n",
    "                zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n",
    "            batch_zx.append(zx)\n",
    "            batch_zy.append(zy)\n",
    "            \n",
    "        return batch_zx, batch_zy\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "test_gen = CustomedImageDataGenerator(\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    #rotation_range=15,\n",
    "    # randomly shift images horizontally\n",
    "    #width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    #height_shift_range=0.1,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.5,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0\n",
    ")\n",
    "print(y_train[0:1])\n",
    "xx,yy=test_gen.flow(x_train[:1],y_train[:1])\n",
    "print(yy)\n",
    "xx = (xx*255)\n",
    "xx= xx.astype(np.int16)\n",
    "#yy = yy*200.\n",
    "for i,x in enumerate(xx):\n",
    "    x=x.transpose((1,2,0))\n",
    "    cv2.imwrite(f\"./test{i}.jpg\",x)\n",
    "    check_y_move(f\"./test{i}.jpg\", yy[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.25059574"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "160*1.08824531-8.86865386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/naka345/work/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/naka345/work/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (2, 2), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4*2))\n",
    "#model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "False\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_validation_split', 'apply_transform', 'brightness_range', 'channel_axis', 'channel_shift_range', 'col_axis', 'cval', 'data_format', 'dtype', 'featurewise_center', 'featurewise_std_normalization', 'fill_mode', 'fit', 'flow', 'flow_from_dataframe', 'flow_from_directory', 'get_random_transform', 'height_shift_range', 'horizontal_flip', 'label_x', 'label_y', 'mean', 'preprocessing_function', 'principal_components', 'random_transform', 'rescale', 'rotation_range', 'row_axis', 'samplewise_center', 'samplewise_std_normalization', 'shear_range', 'standardize', 'std', 'vertical_flip', 'width_shift_range', 'x_ttt', 'y_ttt', 'zca_epsilon', 'zca_whitening', 'zoom_range']\n",
      "[10 24 13  2 26 15 23 20 18 17 19  7 16  3  0 27]\n",
      "[[0.80720721 0.80825566 0.88288288 0.80292943 0.80720721 0.90146471\n",
      "  0.88048048 0.89480692]\n",
      " [0.68       0.7862069  0.8        0.7816092  0.68275862 0.88735632\n",
      "  0.8        0.88505747]]\n",
      "<class 'numpy.ndarray'>\n",
      "[[0.19279279 0.80825566 0.11711712 0.80292943 0.19279279 0.90146471\n",
      "  0.11951952 0.89480692]\n",
      " [0.68       0.7862069  0.8        0.7816092  0.68275862 0.88735632\n",
      "  0.8        0.88505747]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naka345/work/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/naka345/work/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=128, epochs=10)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/128 [..............................] - ETA: 2:35 - loss: 56.3991 - acc: 0.1250    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-59bb8c46e5c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit_generator(test_gen.flow(x_train[0:2], y_train[0:2]),\n\u001b[1;32m      3\u001b[0m                              \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                             \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                    )\n\u001b[1;32m      6\u001b[0m                              \u001b[0;31m#validation_data=(X_val, y_val))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/venv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0])\n",
    "model.fit_generator(test_gen.flow(x_train[0:2], y_train[0:2]),\n",
    "                             steps_per_epoch=x_train.shape[0],\n",
    "                            nb_epoch=10\n",
    "                   )\n",
    "                             #validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 200, 200)\n",
      "(1, 8)\n",
      "[[[[0.7831765  0.7809693  0.7807055  ... 0.5886467  0.6010285\n",
      "    0.61341035]\n",
      "   [0.80233943 0.7758687  0.741013   ... 0.6219141  0.5707892\n",
      "    0.51966435]\n",
      "   [0.71016127 0.69064933 0.6879954  ... 0.17349595 0.15951648\n",
      "    0.14553703]\n",
      "   ...\n",
      "   [0.10980392 0.10980392 0.10980392 ... 0.45490196 0.45490196\n",
      "    0.45490196]\n",
      "   [0.10980392 0.10980392 0.10980392 ... 0.45490196 0.45490196\n",
      "    0.45490196]\n",
      "   [0.10980392 0.10980392 0.10980392 ... 0.45490196 0.45490196\n",
      "    0.45490196]]\n",
      "\n",
      "  [[0.8235705  0.8229995  0.82622594 ... 0.63312244 0.6439066\n",
      "    0.65469074]\n",
      "   [0.8533198  0.8268491  0.7919934  ... 0.65168625 0.59936315\n",
      "    0.54704005]\n",
      "   [0.7606373  0.7399271  0.7360988  ... 0.19141929 0.17584218\n",
      "    0.16026507]\n",
      "   ...\n",
      "   [0.13725491 0.13725491 0.13725491 ... 0.4117647  0.4117647\n",
      "    0.4117647 ]\n",
      "   [0.13725491 0.13725491 0.13725491 ... 0.4117647  0.4117647\n",
      "    0.4117647 ]\n",
      "   [0.13725491 0.13725491 0.13725491 ... 0.4117647  0.4117647\n",
      "    0.4117647 ]]\n",
      "\n",
      "  [[0.8584718  0.855966   0.8486106  ... 0.7200427  0.73122627\n",
      "    0.7424098 ]\n",
      "   [0.8847798  0.8578495  0.8155228  ... 0.74028194 0.6867606\n",
      "    0.63323927]\n",
      "   [0.79262805 0.77186716 0.76245743 ... 0.26900843 0.2526325\n",
      "    0.23625655]\n",
      "   ...\n",
      "   [0.1764706  0.1764706  0.1764706  ... 0.34117648 0.34117648\n",
      "    0.34117648]\n",
      "   [0.1764706  0.1764706  0.1764706  ... 0.34117648 0.34117648\n",
      "    0.34117648]\n",
      "   [0.1764706  0.1764706  0.1764706  ... 0.34117648 0.34117648\n",
      "    0.34117648]]]]\n",
      "[[0.68       0.7862069  0.8        0.7816092  0.68275862 0.88735632\n",
      "  0.8        0.88505747]]\n",
      "[[0.68       0.7862069  0.8        0.7816092  0.68275862 0.88735632 0.8        0.88505747]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:1].shape)\n",
    "print(y_train[:1].shape)\n",
    "for x_batch, y_batch in datagen.flow(x_train[:1], y_train[:1], batch_size=1):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    #print('[[0.68       0.7862069  0.8        0.7816092  0.68275862 0.88735632 0.8        0.88505747]]')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_affine_transform(x, y, theta=0, tx=0, ty=0, shear=0, zx=1, zy=1,\n",
    "                           row_axis=1, col_axis=2, channel_axis=2,\n",
    "                           fill_mode='nearest', cval=0., order=1):\n",
    "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
    "    # Arguments\n",
    "        x: 2D numpy array, single image.\n",
    "        theta: Rotation angle in degrees.\n",
    "        tx: Width shift.\n",
    "        ty: Heigh shift.\n",
    "        shear: Shear angle in degrees.\n",
    "        zx: Zoom in x direction.\n",
    "        zy: Zoom in y direction\n",
    "        row_axis: Index of axis for rows in the input image.\n",
    "        col_axis: Index of axis for columns in the input image.\n",
    "        channel_axis: Index of axis for channels in the input image.\n",
    "        fill_mode: Points outside the boundaries of the input\n",
    "            are filled according to the given mode\n",
    "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
    "        cval: Value used for points outside the boundaries\n",
    "            of the input if `mode='constant'`.\n",
    "        order int: order of interpolation\n",
    "    # Returns\n",
    "        The transformed version of the input.\n",
    "    \"\"\"\n",
    "    if scipy is None:\n",
    "        raise ImportError('Image transformations require SciPy. '\n",
    "                          'Install SciPy.')\n",
    "    transform_matrix = None\n",
    "    if theta != 0:\n",
    "        theta = np.deg2rad(theta)\n",
    "        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                    [np.sin(theta), np.cos(theta), 0],\n",
    "                                    [0, 0, 1]])\n",
    "        transform_matrix = rotation_matrix\n",
    "\n",
    "    if tx != 0 or ty != 0:\n",
    "        shift_matrix = np.array([[1, 0, tx],\n",
    "                                 [0, 1, ty],\n",
    "                                 [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shift_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
    "\n",
    "    if shear != 0:\n",
    "        shear = np.deg2rad(shear)\n",
    "        shear_matrix = np.array([[1, -np.sin(shear), 0],\n",
    "                                 [0, np.cos(shear), 0],\n",
    "                                 [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = shear_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, shear_matrix)\n",
    "\n",
    "    if zx != 1 or zy != 1:\n",
    "        zoom_matrix = np.array([[zx, 0, 0],\n",
    "                                [0, zy, 0],\n",
    "                                [0, 0, 1]])\n",
    "        if transform_matrix is None:\n",
    "            transform_matrix = zoom_matrix\n",
    "        else:\n",
    "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
    "            \n",
    "    if transform_matrix is not None:\n",
    "        h, w = x.shape[row_axis], x.shape[col_axis]\n",
    "        '''\n",
    "        y_transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h,w)\n",
    "        \n",
    "        transform_matrix = transform_matrix_offset_center(\n",
    "            transform_matrix, h, w)\n",
    "        '''\n",
    "\n",
    "        x = np.rollaxis(x, channel_axis, 0)\n",
    "        final_affine_matrix = transform_matrix[:2, :2]\n",
    "        final_offset = transform_matrix[:2, 2]\n",
    "        \n",
    "        print(f'final_affine_matrix {final_affine_matrix}')\n",
    "        print(f'final_offset {final_offset}')\n",
    "        channel_images = [scipy.ndimage.interpolation.affine_transform(\n",
    "            x_channel,\n",
    "            final_affine_matrix,\n",
    "            final_offset,\n",
    "            order=order,\n",
    "            mode=fill_mode,\n",
    "            cval=cval) for x_channel in x]\n",
    "\n",
    "        y = transform_y_label(transform_matrix, y)\n",
    "        \n",
    "        x = np.stack(channel_images, axis=0)\n",
    "        x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "    return x,y\n",
    "\n",
    "def transform_y_label(matrix, y):\n",
    "        y_x = y[::2]\n",
    "        y_y = y[1::2]\n",
    "        y_z = np.ones(4)\n",
    "        y = np.array([y_x, y_y,y_z])\n",
    "        print(y)\n",
    "        #matrix[:2,2] = matrix[:2, 2]/200\n",
    "        print(matrix)\n",
    "        matrix.astype(np.float32)\n",
    "        y.astype(np.float32)\n",
    "        y_all =  np.dot(matrix, y)\n",
    "\n",
    "        return_y = np.arange(8, dtype='float32')\n",
    "\n",
    "        for i in range(y_all[0].shape[0]):\n",
    "            return_y[i*2] = y_all[0][i]\n",
    "            return_y[(i*2)+1] = y_all[1][i]\n",
    "        print(return_y)\n",
    "        return return_y\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    return transform_matrix\n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    transform_matrix[:2, 2] = transform_matrix[:2, 2] *\n",
    "    return transform_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_y_move(image_path, y_label):\n",
    "    im = cv2.imread(image_path)\n",
    "\n",
    "    cv2.drawMarker(im,(int(y_label[0]),int(y_label[1])),(255,0,0), markerType=cv2.MARKER_STAR)\n",
    "    cv2.drawMarker(im,(int(y_label[2]),int(y_label[3])),(0,255,0), markerType=cv2.MARKER_STAR)\n",
    "    cv2.drawMarker(im,(int(y_label[4]),int(y_label[5])),(0,0,255), markerType=cv2.MARKER_STAR)\n",
    "    cv2.drawMarker(im,(int(y_label[6]),int(y_label[7])),(0,0,0), markerType=cv2.MARKER_STAR)\n",
    "    cv2.imwrite(image_path,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reciprocal(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
